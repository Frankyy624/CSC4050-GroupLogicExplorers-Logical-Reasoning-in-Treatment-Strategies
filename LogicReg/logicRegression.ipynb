{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logreg_anneal_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_anneal_control(start=0, end=0, iter=0, earlyout=0, update=0):\n",
    "    if isinstance(start, dict):\n",
    "        if 'end' in start and len(start['end']) > 0:\n",
    "            end = start['end']\n",
    "        if 'iter' in start and len(start['iter']) > 0:\n",
    "            iter = start['iter']\n",
    "        if 'earlyout' in start and len(start['earlyout']) > 0:\n",
    "            earlyout = start['earlyout']\n",
    "        if 'update' in start and len(start['update']) > 0:\n",
    "            update = start['update']\n",
    "        if 'start' in start and len(start['start']) > 0:\n",
    "            start = start['start']\n",
    "        else:\n",
    "            start = 0\n",
    "    if iter < 100 and (start != 0 or end != 0):\n",
    "        raise ValueError(\"not enough repetitions\")\n",
    "    if start < end:\n",
    "        raise ValueError(\"starting temperature below ending temperature\")\n",
    "    return {'start': start, 'end': end, 'iter': iter, 'earlyout': earlyout, 'update': update}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logreg_tree_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_tree_control(treesize=8, opers=1, minmass=0, n1=None):\n",
    "    if isinstance(treesize, dict):\n",
    "        if 'opers' in treesize and len(treesize['opers']) > 0:\n",
    "            opers = treesize['opers']\n",
    "        if 'minmass' in treesize and len(treesize['minmass']) > 0:\n",
    "            minmass = treesize['minmass']\n",
    "        if 'treesize' in treesize and len(treesize['treesize']) > 0:\n",
    "            treesize = treesize['treesize']\n",
    "        else:\n",
    "            treesize = 16\n",
    "    \n",
    "    treesize = 2 ** np.floor(np.log2(np.abs(treesize + 0.0001)))\n",
    "    \n",
    "    if opers != 2 and opers != 3 and opers != 4:\n",
    "        opers = 1\n",
    "    \n",
    "    if minmass < 0:\n",
    "        minmass = 0\n",
    "    \n",
    "    if n1 is not None:\n",
    "        if minmass > n1 / 4:\n",
    "            raise ValueError(\"minmass should be at most samplesize/4\")\n",
    "    \n",
    "    return {'treesize': treesize, 'opers': opers, 'minmass': minmass}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logreg_mc_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_mc_control(nburn=1000, niter=25000, hyperpars=0, update=0, output=4):\n",
    "    if isinstance(nburn, dict):\n",
    "        if 'niter' in nburn and len(nburn['niter']) > 0:\n",
    "            niter = nburn['niter']\n",
    "        if 'hyperpars' in nburn and len(nburn['hyperpars']) > 0:\n",
    "            hyperpars = nburn['hyperpars']\n",
    "        if 'output' in nburn and len(nburn['output']) > 0:\n",
    "            output = nburn['output']\n",
    "        if 'update' in nburn and len(nburn['update']) > 0:\n",
    "            update = nburn['update']\n",
    "        if 'nburn' in nburn and len(nburn['nburn']) > 0:\n",
    "            nburn = nburn['nburn']\n",
    "        else:\n",
    "            nburn = 1000\n",
    "    hyperpars = np.concatenate([hyperpars, np.zeros(4)])[:4]\n",
    "    return {'nburn': nburn, 'niter': niter, 'hyperpars': hyperpars, 'update': update, 'output': output}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# savefit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'C:/Users/asus/Desktop/CSC4050/LogicReg/R/savefit/'\n",
    "tree1 = pd.read_csv(root+'savefit1_tree1.csv')\n",
    "tree2 = pd.read_csv(root+'savefit1_tree2.csv')\n",
    "\n",
    "response = pd.read_csv(root+'savefit1_response.csv')\n",
    "response = response.values.squeeze()\n",
    "\n",
    "censor = pd.read_csv(root+'savefit1_censor.csv')\n",
    "censor = censor.values.squeeze()\n",
    "\n",
    "weight = pd.read_csv(root+'savefit1_weight.csv')\n",
    "weight = weight.values.squeeze()\n",
    "\n",
    "binary = pd.read_csv(root+'savefit1_binary.csv', header=None, skiprows=[0])\n",
    "binary = binary.values\n",
    "\n",
    "logreg_savefit1 = {\n",
    "    'class': 'logreg',\n",
    "    'nsample': 500,\n",
    "    'nbinary': 20,\n",
    "    'nseparate': 0,\n",
    "    'type': 'regression',\n",
    "    'select': 'single.model',\n",
    "    'anneal.control':{\n",
    "        'start': -1,\n",
    "        'end': -4,\n",
    "        'iter': 25000,\n",
    "        'earlyout': 0,\n",
    "        'update': 1000,\n",
    "    },\n",
    "    'tree.control': {\n",
    "        'treesize': 8,\n",
    "        'opers': 1,\n",
    "        'minmass': 0,\n",
    "        'operators': 'both',\n",
    "    },\n",
    "    'seed': 0,\n",
    "    'choice': 1,\n",
    "    'nleaves': -1,\n",
    "    'ntrees': 2,\n",
    "    'penalty': 0,\n",
    "    'response': response, # double[500] \n",
    "    'binary':  binary, # double[500*20]: 0 or 1\n",
    "    'separate': 0, \n",
    "    'censor': censor, # double[500]\n",
    "    'weight': weight, # double[500]\n",
    "    'model': {\n",
    "        'class': 'logregmodel',\n",
    "        'ntrees': np.array([2, 2]), # dtype=np.float64\n",
    "        'nleaves': np.array([-1, -1]), # dtype=np.float64\n",
    "        'score': np.array([0.966493], dtype=np.float64),\n",
    "        'coef': np.array([1.982887, -1.304364, 2.153445], dtype=np.float64),\n",
    "        'trees': [\n",
    "            {\n",
    "                'class': 'logregtree',\n",
    "                'whichtree': 1,\n",
    "                'coef': np.array([-1.304364], dtype=np.float64),\n",
    "                'trees': tree1.values, # A data.frame with 15 rows and columns(number,conc,knot,neg,pick)\n",
    "            },\n",
    "            {\n",
    "                'class': 'logregtree',\n",
    "                'whichtree': 2,\n",
    "                'coef': np.array([2.153445], dtype=np.float64),\n",
    "                'trees': tree2.values, # A data.frame with 15 rows and columns(number,conc,knot,neg,pick)\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    # 'call': {\n",
    "    #     'func': logreg,\n",
    "    #     'args': {\n",
    "    #         'resp': logreg_testdat[:,0],\n",
    "    #         'bin': logreg_testdat[:,1:21],\n",
    "    #         'type': 2,\n",
    "    #         'select': 1,\n",
    "    #         'ntrees': 2,\n",
    "    #         'anneal_control': myanneal,\n",
    "    #     }\n",
    "    # }\n",
    "}\n",
    "\n",
    "# # apply 'call'\n",
    "# logreg_savefit1['call']['func'](**logreg_savefit1['call']['args'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_logreg(ltree, data):\n",
    "   '''\n",
    "   ltree: 'logreggtree' or 'logregmodel', part of result of an object of class logreg, generated with select=1 (single model fit), select=2 (multiple model fit),\n",
    "   or select=6 (greedy stepwise fit).\n",
    "   \n",
    "   data: a data frame on which the logic tree is to be evaluated. Binary, have the same number of column as the bin component of the original logreg fit.\n",
    "   '''\n",
    "   if ltree['class'] == \"logregtree\": # using dictionary\n",
    "      ltree = ltree['trees']  \n",
    "      nn = np.ones((data.shape[0], ltree.shape[0])) \n",
    "      for i in range(ltree.shape[0]):\n",
    "         if ltree[i, 1] == 3: # Check if node type is 3 (indicating a variable)\n",
    "            nn[:, i] = data[:, ltree[i, 2]-1] # -1\n",
    "            if ltree[i, 3] == 1: # 0: regular variable; 1: its complement\n",
    "               nn[:, i] = 1 - nn[:, i] \n",
    "      ox = ltree.shape[0] # Backward pass through the trees for and and or nodes\n",
    "      ox = ox // 2\n",
    "      for i in range(ox-1, -1, -1):\n",
    "         if ltree[i, 1] == 1: # Check if node type is 1 (indicating an and node) \n",
    "            nn[:, i] = nn[:, 2*(i+1)-1] * nn[:, 2*(i+1)]\n",
    "         if ltree[i, 1] == 2: # Check if node type is 2 (indicating a or node)\n",
    "            nn[:, i] = nn[:, 2*(i+1)-1] + nn[:, 2*(i+1)]\n",
    "      nn = np.clip(nn, None, 1) # Set values greater than 1 to 1\n",
    "      if np.count_nonzero(ltree) == 0: # Check if all nodes in ltree are zeros\n",
    "         nn[:, 0] = 0 ##\n",
    "      return nn[:, 0]\n",
    "   \n",
    "   else:\n",
    "      if ltree['class'] == \"logregmodel\": # If ltree is an object of class logregmodel, recursively evaluate each tree\n",
    "         n1 = eval_logreg(ltree['trees'][0], data)\n",
    "         if ltree['ntrees'][0] > 1:\n",
    "            for i in range(1, ltree['ntrees'][0]):\n",
    "               n1 = np.column_stack((n1, eval_logreg(ltree['trees'][i], data))) # combine the results\n",
    "         return n1\n",
    "      else:\n",
    "         raise ValueError(\"ltree not of class logregtree of logregmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_logreg(ltree=logreg_savefit1['model'], data=logreg_savefit1['binary'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frame_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_logreg(fit, msz=None, ntr=None, newbin=None, newresp=None, newsep=None, newcens=None, newweight=None):\n",
    "    \n",
    "    if fit['class'] != \"logreg\": \n",
    "        raise ValueError(\"fit not of class logreg\")\n",
    "\n",
    "    outframe = pd.DataFrame() \n",
    "    # If 'newbin' is missing, use the original data\n",
    "    if newbin is None: # missing(newbin)\n",
    "        outframe['y'] = fit['response']  \n",
    "        outframe['wgt'] = fit['weight'] \n",
    "        if fit['type'] == \"proportional.hazards\" or fit['type'] == \"exponential.survival\":\n",
    "            outframe['cens'] = fit['censor']\n",
    "        if fit['nseparate'] > 0: # nsep=?nseparate??? \n",
    "            outframe = pd.concat([outframe, fit['separate']], axis=1)\n",
    "        binhere = fit['binary']\n",
    "\n",
    "    else:\n",
    "        binhere = newbin # if 'newbin' is specified\n",
    "        # lbinhere = len(binhere)\n",
    "        if isinstance(binhere, pd.DataFrame):\n",
    "            binhere = binhere.values\n",
    "        if not isinstance(binhere, np.ndarray):   # use array to substitude matrix\n",
    "            binhere = np.array(binhere).reshape((-1,fit['nbinary']))\n",
    "        \n",
    "        n1 = binhere.shape[0]\n",
    "        n2 = binhere.shape[1]\n",
    "\n",
    "        if n2 != fit['nbinary']:\n",
    "            raise ValueError(\"new number of binary predictors doesn't match fit\")\n",
    "\n",
    "        if newweight is not None:\n",
    "            if len(newweight) != n1:\n",
    "                raise ValueError(\"length(newweight) != length(newbin[,1])\")\n",
    "        else:\n",
    "            newweight = np.repeat(1, n1)\n",
    "\n",
    "        if newresp is not None: \n",
    "            if len(newresp) != n1:\n",
    "                raise ValueError(\"length(newresp) != length(newbin[,1])\")\n",
    "            outframe['y'] = newresp\n",
    "            outframe['wgt'] = newweight\n",
    "        else:\n",
    "            outframe['wgt'] = newweight\n",
    "\n",
    "        if fit['type'] == \"proportional.hazards\" or fit['type'] == \"exponential.survival\": # newcens for proportional hazards models and exponential survival models only.\n",
    "            if newcens is None:\n",
    "                warnings.warn(\"Warning: newcens missing, taking all censoring indicators to be 1\")\n",
    "                outframe['cens'] = np.repeat(1, n1)\n",
    "            else:\n",
    "                if len(newcens) != n1:\n",
    "                    raise ValueError(\"length(newcens) != length(newbin[,1])\")\n",
    "                outframe['cens'] = newcens\n",
    "\n",
    "        if fit['nseparate'] > 0:\n",
    "            if newsep is None:\n",
    "                raise ValueError(\"you need to specify newsep\")\n",
    "            if not isinstance(newsep, np.ndarray): # use array to substitude matrix\n",
    "                newsep = np.array(newsep).reshape((-1,fit['nseparate']))\n",
    "            if isinstance(newsep, pd.DataFrame):\n",
    "                newsep = newsep.values\n",
    "            if newsep.shape[0] != n1:\n",
    "                raise ValueError(\"length(newsep[,1]) != length(newbin[,1])\")\n",
    "            if newsep.shape[1] != fit['nseparate']:\n",
    "                raise ValueError(\"new number of separate predictors doesn't match fit\")\n",
    "            outframe = pd.concat([outframe, pd.DataFrame(newsep)], axis=1)\n",
    "\n",
    "    if fit['choice'] != 1 and fit['choice'] != 2 and fit['choice'] != 6: # check the type of model\n",
    "        raise ValueError(\"fit$choice needs to be 1, 2, or 6\")\n",
    "\n",
    "    if fit['choice'] == 1:\n",
    "        ntr = fit['ntrees']\n",
    "        msz = fit['nleaves'] \n",
    "        for j in range(ntr):\n",
    "            mtree = fit['model']['trees'][j]['trees']\n",
    "            if msz < 0:\n",
    "                msz = 0.5 * (mtree.shape[0]+1)\n",
    "            if mtree[0, 1] == 0: # the first node is empty\n",
    "                outframe['tmp'] = 0\n",
    "            else:\n",
    "                tmp = eval_logreg(fit['model']['trees'][j], binhere)\n",
    "                outframe['tmp'] = tmp\n",
    "            col_name = f\"tree{msz}.{ntr}.{j}\"\n",
    "            outframe.rename(columns={\"tmp\": col_name}, inplace=True)\n",
    "\n",
    "    else:\n",
    "        for i in range(len(fit['nmodels'])): ## nmodels/alltrees\n",
    "            xfit = fit['alltrees'][i]\n",
    "            ntrx = xfit['ntrees']\n",
    "            mszx = xfit['nleaves']\n",
    "            l1 = 1\n",
    "            \n",
    "            if ntr is not None and fit['choice'] == 2:\n",
    "                l1 = sum(ntrx == ntr)\n",
    "            if msz is not None:\n",
    "                l1 *=  sum(mszx == msz)\n",
    "            if l1 > 0:\n",
    "                for j in range(ntrx):\n",
    "                    if xfit['trees'][j]['trees'][0, 1] == 0:\n",
    "                        outframe['tmp'] = 0\n",
    "                    else:\n",
    "                        tmp = eval_logreg(xfit['trees'][j], binhere)\n",
    "                        outframe['tmp'] = tmp\n",
    "                    col_name = f\"tree{mszx}.{ntrx}.{j}\"\n",
    "                    outframe.rename(columns={\"tmp\": col_name}, inplace=True)\n",
    "\n",
    "    return outframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>wgt</th>\n",
       "      <th>tree8.0.2.0</th>\n",
       "      <th>tree8.0.2.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.171474</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.904972</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.205592</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.692276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.939746</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.626938</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3.299834</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>5.651117</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>4.058269</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>4.368515</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y  wgt  tree8.0.2.0  tree8.0.2.1\n",
       "0    2.171474    1          1.0          1.0\n",
       "1    3.904972    1          0.0          1.0\n",
       "2    2.205592    1          0.0          0.0\n",
       "3    3.692276    1          0.0          1.0\n",
       "4    1.939746    1          0.0          0.0\n",
       "..        ...  ...          ...          ...\n",
       "495  0.626938    1          0.0          0.0\n",
       "496  3.299834    1          0.0          1.0\n",
       "497  5.651117    1          0.0          1.0\n",
       "498  4.058269    1          0.0          1.0\n",
       "499  4.368515    1          0.0          1.0\n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_logreg(fit=logreg_savefit1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unstrip(x):\n",
    "    dd = x.shape\n",
    "    y = x\n",
    "    if len(dd) == 2:\n",
    "        dd2 = dd[1]\n",
    "        if dd2 == 1:\n",
    "            y = x[:, 0]\n",
    "        if dd2 == 2:\n",
    "            y = np.column_stack((x[:, 0], x[:, 1])) # to test\n",
    "        if dd2 > 2:\n",
    "            y = np.column_stack((x[:, 0], x[:, 1], x[:, 2]))\n",
    "        if dd2 > 3:\n",
    "            for i in range(3, dd2):\n",
    "                y = np.column_stack((y, x[:, i]))\n",
    "        return y\n",
    "\n",
    "    if len(dd) == 1 or len(dd) == 0:\n",
    "        y = np.array(x).flatten()\n",
    "        # names(y) = NULL 移除列名\n",
    "    return y\n",
    "\n",
    "\n",
    "def predict_logreg(object, msz=None, ntr=None, newbin=None, newsep=None, **kwargs):\n",
    "    if object['class'] != \"logreg\":\n",
    "        raise ValueError(\"object not of class logreg\")\n",
    "        \n",
    "    if object['choice'] > 2 and object['choice'] != 6:\n",
    "        raise ValueError(\"object$choice needs to be 1, 2, or 6\")\n",
    "\n",
    "    if newbin is not None:\n",
    "        if msz is None and ntr is None and newsep is None:\n",
    "            y = frame_logreg(fit=object, newbin=newbin)\n",
    "        elif msz is None and ntr is None and newsep is not None:\n",
    "            y = frame_logreg(fit=object, newbin=newbin, newsep=newsep)\n",
    "        elif msz is None and ntr is not None and newsep is None:\n",
    "            y = frame_logreg(fit=object, newbin=newbin, ntr=ntr)\n",
    "        elif msz is None and ntr is not None and newsep is not None:\n",
    "            y = frame_logreg(fit=object, newbin=newbin, newsep=newsep, ntr=ntr)\n",
    "        elif msz is not None and ntr is None and newsep is None:\n",
    "            y = frame_logreg(fit=object, newbin=newbin, msz=msz)\n",
    "        elif msz is not None and ntr is None and newsep is not None:\n",
    "            y = frame_logreg(fit=object, newbin=newbin, newsep=newsep, msz=msz)\n",
    "        elif msz is not None and ntr is not None and newsep is None:\n",
    "            y = frame_logreg(fit=object, newbin=newbin, ntr=ntr, msz=msz)\n",
    "        elif msz is not None and ntr is not None and newsep is not None:\n",
    "            y = frame_logreg(fit=object, newbin=newbin, newsep=newsep, ntr=ntr, msz=msz)\n",
    "    else:\n",
    "        if msz is None and ntr is None:\n",
    "            y = frame_logreg(fit=object)[:, 1:] # exclude the first column\n",
    "        elif msz is None and ntr is not None:\n",
    "            y = frame_logreg(fit=object, ntr=ntr)[:, 1:]\n",
    "        elif msz is not None and ntr is None:\n",
    "            y = frame_logreg(fit=object, msz=msz)[:, 1:]\n",
    "        elif msz is not None and ntr is not None:\n",
    "            y = frame_logreg(fit=object, ntr=ntr, msz=msz)[:, 1:]\n",
    "\n",
    "    iik = 0\n",
    "    if msz is None and ntr is None and object['select'] == \"greedy\":\n",
    "        iik = 1\n",
    "\n",
    "    ly = len(y[:, 0]) #y=500\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y = np.reshape(unstrip(y), (ly, -1), order='F')\n",
    "\n",
    "    lly = len(y[:, 0])\n",
    "    y = y[:, 1:]\n",
    "    if lly == 1:\n",
    "        y = np.array(y).reshape(1, -1) \n",
    "\n",
    "    if object['type'] == \"proportional.hazards\":\n",
    "        y = y[:, 1:]\n",
    "\n",
    "    z = None\n",
    "    if len(y) == ly:\n",
    "        y = np.array(y).reshape(-1, 1) \n",
    "    \n",
    "    y = np.column_stack((y, np.array([1]*ly))) \n",
    "\n",
    "    if object['select'] == \"single.model\":\n",
    "        z = np.array([object['model']['coef'][0]] * len(y[:, 0])) # array([coef, coef, ..., coef])\n",
    "        for i in range(1, len(object['model']['coef'])):\n",
    "            z += object['model']['coef'][i] * y[:, i - 1]\n",
    "\n",
    "    if object['select'] == \"multiple.models\" or object['select'] == \"greedy\":\n",
    "        if msz is None:\n",
    "            msz = range(min(object['nleaves']), max(object['nleaves']))\n",
    "        if ntr is None:\n",
    "            ntr = range(min(object['ntrees']), max(object['ntrees']))\n",
    "        z = None\n",
    "\n",
    "        if object['nseparation'] > 0:\n",
    "            y1 = y[:, :object['nseparation']]\n",
    "            y = y[:, object['nseparation']:]\n",
    "\n",
    "        jk = 0\n",
    "        for i in range(object['nmodels']):\n",
    "            nt1 = object['alltrees'][i]['ntrees']\n",
    "            ms1 = object['alltrees'][i]['nleaves']\n",
    "\n",
    "            if sum(nt1 == ntr) * sum(ms1 == msz) > 0 or iik == 1:\n",
    "                jk += 1\n",
    "                if ly == 1:\n",
    "                    y = np.array(y).reshape(1, -1) \n",
    "                else:\n",
    "                    if len(y) == ly:\n",
    "                        y = np.array(y).reshape(-1, 1) \n",
    "                \n",
    "                y3 = y[:, :nt1]\n",
    "                if i != object['nmodels']:\n",
    "                    y = y[:, nt1:]\n",
    "\n",
    "                if nt1 == 1:\n",
    "                    y3 = np.array(y3).reshape(-1, 1) \n",
    "\n",
    "                if object['nseparation'] > 0:\n",
    "                    y3 = np.column_stack((y1, y3)) ##\n",
    "\n",
    "                cc = object['alltrees'][i]['coef']\n",
    "                z2 = cc[0]\n",
    "                if len(cc) > 1:\n",
    "                    for ii in range(1, len(cc)):\n",
    "                        z2 += cc[ii] * y3[:, ii - 1]\n",
    "\n",
    "                str_v = f\"tr{nt1}.lf{ms1}\"\n",
    "                if z is not None:\n",
    "                    z = df = pd.DataFrame({'z': z, 'z2': z2})\n",
    "                else:\n",
    "                    z = pd.DataFrame({'z2': z2})\n",
    "\n",
    "                z.columns[jk-1] = str_v \n",
    "\n",
    "        if object['type'] == \"classification\":\n",
    "            z[z != 0] = 1\n",
    "\n",
    "        if object['type'] == \"logistic\":\n",
    "            z = np.exp(z) / (1 + np.exp(z))\n",
    "\n",
    "    return z"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in logreg function\n",
    "\n",
    "def logreg_binary(x):\n",
    "    l1 = x.shape[0]*x.shape[1]\n",
    "    l2 = np.sum(x == 0)\n",
    "    l3 = np.sum(x == 1)\n",
    "    return l1 == (l2 + l3)\n",
    "\n",
    "def logreg_storetree(x): #input: numpy array\n",
    "    i1 = np.array(x[3:], dtype=float).reshape(-1, 4)\n",
    "    i2 = i1.shape[0]\n",
    "    i3 = pd.DataFrame({'number': np.arange(1, i2 + 1),\n",
    "                       'conc': i1[:, 0],\n",
    "                       'knot': i1[:, 1],\n",
    "                       'neg': i1[:, 2],\n",
    "                       'pick': i1[:, 3]})\n",
    "    return i3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
